{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_json(\"data/preprocessed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18627, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>date_only</th>\n",
       "      <th>day_name</th>\n",
       "      <th>description</th>\n",
       "      <th>external_picture</th>\n",
       "      <th>fanpagelink</th>\n",
       "      <th>fb_angry</th>\n",
       "      <th>fb_haha</th>\n",
       "      <th>fb_id</th>\n",
       "      <th>fb_like</th>\n",
       "      <th>...</th>\n",
       "      <th>message</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>page_id</th>\n",
       "      <th>preprocessed_name</th>\n",
       "      <th>preprocessed_stem_stop</th>\n",
       "      <th>shares</th>\n",
       "      <th>time_created</th>\n",
       "      <th>time_only</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>facebook_fanpage_buzzfeed</td>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>Saturday</td>\n",
       "      <td></td>\n",
       "      <td>https://external.xx.fbcdn.net/safe_image.php?d...</td>\n",
       "      <td>https://www.facebook.com/BuzzFeed/posts/101541...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21898300328_10154172924370329</td>\n",
       "      <td>6591</td>\n",
       "      <td>...</td>\n",
       "      <td>The cold never bothered them anyway.</td>\n",
       "      <td>A Surprise Snowstorm Turned This Wedding Into ...</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>a surprise snowstorm turned this wedding into ...</td>\n",
       "      <td>surpris snowstorm turn wed winter wonderland</td>\n",
       "      <td>158</td>\n",
       "      <td>2015-12-19T12:16:01</td>\n",
       "      <td>12:16:01</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        database   date_only  day_name description  \\\n",
       "10000  facebook_fanpage_buzzfeed  2015-12-19  Saturday               \n",
       "\n",
       "                                        external_picture  \\\n",
       "10000  https://external.xx.fbcdn.net/safe_image.php?d...   \n",
       "\n",
       "                                             fanpagelink  fb_angry  fb_haha  \\\n",
       "10000  https://www.facebook.com/BuzzFeed/posts/101541...         0        0   \n",
       "\n",
       "                               fb_id  fb_like  ...   \\\n",
       "10000  21898300328_10154172924370329     6591  ...    \n",
       "\n",
       "                                    message  \\\n",
       "10000  The cold never bothered them anyway.   \n",
       "\n",
       "                                                    name  num_comments  \\\n",
       "10000  A Surprise Snowstorm Turned This Wedding Into ...           120   \n",
       "\n",
       "       page_id                                  preprocessed_name  \\\n",
       "10000        1  a surprise snowstorm turned this wedding into ...   \n",
       "\n",
       "                             preprocessed_stem_stop  shares  \\\n",
       "10000  surpris snowstorm turn wed winter wonderland     158   \n",
       "\n",
       "              time_created time_only  type  \n",
       "10000  2015-12-19T12:16:01  12:16:01  link  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_xy = dataset[[\"preprocessed_stem_stop\",\"highest_reaction\"]]  # Only 2 columns are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"output/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "dataset_xy[\"preprocessed_stem_stop\"].to_csv(output_dir + \"documents.txt\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction again, this time using BTM (Biterm Topic Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm gonna use the titles saved in doc_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the source code from its creator\n",
    "\n",
    "https://github.com/xiaohuiyan/BTM\n",
    "\n",
    "And because input docs must be indexed there's 2 files we need to create\n",
    "\n",
    "`\n",
    "doc_wids.txt    output docs after indexing, each line is a doc with the format \"wordId wordId ...\"\n",
    "voca.txt        output vocabulary file, each line is a word with the format \"wordId    word\"\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# translate word into id in documents\n",
    "import sys\n",
    "\n",
    "class DocumentIndex():\n",
    "    \n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "        self.w2id = {}\n",
    "\n",
    "    def indexFile(self, pt, res_pt):\n",
    "        print('index file: ', pt)\n",
    "        wf = open(res_pt, 'w')\n",
    "        for l in open(pt):\n",
    "            ws = l.strip().split()\n",
    "            for w in ws:\n",
    "                if not w in self.w2id:\n",
    "                    self.w2id[w] = len(self.w2id)\n",
    "            wids = [self.w2id[w] for w in ws]        \n",
    "            wf.write(\"%s\\n\" % ' '.join(map(str, wids)))\n",
    "        print('write file: ', res_pt)\n",
    "\n",
    "    def write_w2id(self, res_pt):\n",
    "        print('write:', res_pt)\n",
    "        wf = open(res_pt, 'w')\n",
    "        for w, wid in sorted(self.w2id.items(), key=lambda d:d[1]):\n",
    "            wf.write('%d\\t%s\\n' % (wid, w))\n",
    "    \n",
    "    def create_index(self, doc_pt, dwid_pt, voca_pt):\n",
    "        self.indexFile(self.output_dir + doc_pt, self.output_dir + dwid_pt)\n",
    "        print('n(w)=', len(self.w2id))\n",
    "        self.write_w2id(self.output_dir + voca_pt)\n",
    "\n",
    "        \n",
    "    def vocabulary_size(self):\n",
    "        return len(self.w2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index file:  output/documents.txt\n",
      "write file:  output/doc_wids.txt\n",
      "n(w)= 11629\n",
      "write: output/voca.txt\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"output/\"\n",
    "input_vocab = \"voca.txt\"\n",
    "input_docs = \"doc_wids.txt\"\n",
    "\n",
    "document_index = DocumentIndex(output_dir)\n",
    "document_index.create_index(\"documents.txt\", input_docs, input_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "`\n",
    "K           int, number of topics\n",
    "W           int, size of vocabulary\n",
    "alpha       double, Symmetric Dirichlet prior of P(z), like 1\n",
    "beta        double, Symmetric Dirichlet prior of P(w|z), like 0.01\n",
    "n_iter      int, number of iterations of Gibbs sampling\n",
    "save_step   int, steps to save the results\n",
    "docs_pt     string, path of training docs\n",
    "model_dir   string, output directory\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BtmFeatureModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def make_x(self, model_dir, K, index):\n",
    "        features_path = model_dir + \"k{}.pz_d\".format(K)\n",
    "        features = pd.read_csv(features_path, sep='\\s+', header=None)\n",
    "        features.set_index(index)\n",
    "        return features\n",
    "        \n",
    "    def model_initialization(self, K, W, alpha, beta, niter, save_step,\n",
    "                             docs_pt, model_dir):\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "\n",
    "        # TOPIC MODELING\n",
    "        command_initialize = (\"BTM/src/btm est {} {} {} {} {} {} {} {}\"). \\\n",
    "                        format(K, W, alpha, beta, niter, save_step,\n",
    "                               docs_pt, model_dir)\n",
    "        self.run_command(command_initialize)\n",
    "        \n",
    "    def model_inference(self, type_model, K, docs_pt, model_dir):\n",
    "        # INFERENCE\n",
    "        command_infer = (\"BTM/src/btm inf {} {} {} {}\"). \\\n",
    "                            format(type_model, K, docs_pt, model_dir)\n",
    "        self.run_command(command_infer)\n",
    "        \n",
    "    def run_command(self, command):\n",
    "        print(command)\n",
    "        try:\n",
    "            os.system(command)\n",
    "        except:\n",
    "            print(\"exception\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTM/src/btm est 50 11629 1.0 0.005 1000 501 output/doc_wids.txt output/model/\n"
     ]
    }
   ],
   "source": [
    "save_step = 501\n",
    "input_docs = \"doc_wids.txt\"\n",
    "model_dir = output_dir + \"model/\"\n",
    "docs_pt = output_dir + input_docs\n",
    "\n",
    "# Actual parameters\n",
    "K = 50\n",
    "W = document_index.vocabulary_size()\n",
    "alpha = 50 / K\n",
    "beta = 0.005\n",
    "niter = 1000\n",
    "\n",
    "btm_model = BtmFeatureModel()\n",
    "btm_model.model_initialization(K, W, alpha, beta, niter, save_step,\n",
    "                               docs_pt, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just created a K*M matrix for P(w|z)\n",
    "\n",
    "and a K*1 matrix for P(z)\n",
    "\n",
    "**Then, P(z|d) is inferred by running the same but using other parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "K           int, number of topics, like 20\n",
    "type        string, 4 choices:sum_w, sum_b, lda, mix. sum_b is used in our  paper.\n",
    "docs_pt     string, path of docs to be inferred\n",
    "model_dir   string, output directory\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTM/src/btm inf sum_b 50 output/doc_wids.txt output/model/\n"
     ]
    }
   ],
   "source": [
    "type_model = 'sum_b'\n",
    "btm_model.model_inference(type_model, K, docs_pt, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read that P(z|d) and use it as a features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>6.005900e-08</td>\n",
       "      <td>1.365550e-02</td>\n",
       "      <td>5.836950e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>8.396640e-07</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>1.195330e-07</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.218943</td>\n",
       "      <td>9.707750e-08</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>1.852750e-06</td>\n",
       "      <td>2.531040e-08</td>\n",
       "      <td>1.380720e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.067050e-05</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>4.830390e-08</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>9.594280e-07</td>\n",
       "      <td>0.039269</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5        6   \\\n",
       "0  0.000127  0.010011  0.002454  0.000012  0.001384  0.001637  0.00008   \n",
       "1  0.028168  0.013614  0.000032  0.008730  0.014682  0.004230  0.00141   \n",
       "\n",
       "             7             8             9     ...           40            41  \\\n",
       "0  6.005900e-08  1.365550e-02  5.836950e-08    ...     0.007665  8.396640e-07   \n",
       "1  1.852750e-06  2.531040e-08  1.380720e-02    ...     0.000067  1.067050e-05   \n",
       "\n",
       "         42        43            44        45        46            47  \\\n",
       "0  0.009744  0.008574  1.195330e-07  0.000025  0.218943  9.707750e-08   \n",
       "1  0.004806  0.003968  4.830390e-08  0.000015  0.001124  9.594280e-07   \n",
       "\n",
       "         48        49  \n",
       "0  0.000027  0.000025  \n",
       "1  0.039269  0.000006  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = btm_model.make_x(model_dir, K, dataset_xy.index)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000    0\n",
       "10001    1\n",
       "Name: highest_reaction, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset_xy[\"highest_reaction\"]\n",
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def square(x):\n",
    "#     if x == 0:\n",
    "#         return 1\n",
    "#     return x\n",
    "# y = y.apply(square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with the Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_linear_svc = svm.LinearSVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "from sklearn import cross_validation as cv\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [ 2**j for j in range(1,4) ]\n",
    "}\n",
    "\n",
    "skf = cv.StratifiedKFold(y, n_folds=3)\n",
    "clf_grid = grid_search.GridSearchCV(clf_linear_svc, \n",
    "                                    param_grid = param_grid,\n",
    "                                    scoring=\"accuracy\",\n",
    "                                    n_jobs=1,\n",
    "                                    cv=skf,\n",
    "                                    verbose=3)\n",
    "fitted = clf_grid.fit(X, y)\n",
    "\n",
    "print (\"best_params_: {}\\n\".format(clf_grid.best_params_))\n",
    "print (\"best_score_: {}\\n\".format(clf_grid.best_score_))\n",
    "\n",
    "print (\"best_score_: {}\\n\".format(clf_grid.grid_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_estimators=130 ................................................\n",
      "[CV] ....................... n_estimators=130, score=0.507165 -  12.0s\n",
      "[CV] n_estimators=130 ................................................\n",
      "[CV] ....................... n_estimators=130, score=0.519568 -  11.0s\n",
      "[CV] n_estimators=130 ................................................\n",
      "[CV] ....................... n_estimators=130, score=0.548091 -  10.8s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ....................... n_estimators=150, score=0.508614 -  12.4s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ....................... n_estimators=150, score=0.524561 -  12.5s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ....................... n_estimators=150, score=0.545352 -  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'n_estimators': 150}\n",
      "\n",
      "best_score_: 0.5261716862618779\n",
      "\n",
      "best_score_: [mean: 0.52494, std: 0.01713, params: {'n_estimators': 130}, mean: 0.52617, std: 0.01504, params: {'n_estimators': 150}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [ 130, 150 ]\n",
    "}\n",
    "\n",
    "skf = cv.StratifiedKFold(y, n_folds=3)\n",
    "clf_grid = grid_search.GridSearchCV(clf_rf, \n",
    "                                    param_grid = param_grid,\n",
    "                                    scoring=\"accuracy\",\n",
    "                                    n_jobs=1,\n",
    "                                    cv=skf,\n",
    "                                    verbose=3)\n",
    "fitted = clf_grid.fit(X, y)\n",
    "\n",
    "print (\"best_params_: {}\\n\".format(clf_grid.best_params_))\n",
    "print (\"best_score_: {}\\n\".format(clf_grid.best_score_))\n",
    "\n",
    "print (\"best_score_: {}\\n\".format(clf_grid.grid_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_rbf = svm.SVC( kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 39 candidates, totalling 117 fits\n",
      "[CV] C=2, gamma=1e-09 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-09, score=0.402351 -  18.0s\n",
      "[CV] C=2, gamma=1e-09 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-09, score=0.402319 -  19.0s\n",
      "[CV] C=2, gamma=1e-09 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-09, score=0.402449 -  18.9s\n",
      "[CV] C=2, gamma=1e-08 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-08, score=0.402351 -  19.2s\n",
      "[CV] C=2, gamma=1e-08 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-08, score=0.402319 -  21.0s\n",
      "[CV] C=2, gamma=1e-08 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-08, score=0.402449 -  21.0s\n",
      "[CV] C=2, gamma=1e-07 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-07, score=0.402351 -  22.3s\n",
      "[CV] C=2, gamma=1e-07 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-07, score=0.402319 -  21.8s\n",
      "[CV] C=2, gamma=1e-07 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-07, score=0.402449 -  22.1s\n",
      "[CV] C=2, gamma=1e-06 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-06, score=0.402351 -  22.4s\n",
      "[CV] C=2, gamma=1e-06 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-06, score=0.402319 -  22.7s\n",
      "[CV] C=2, gamma=1e-06 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-06, score=0.402449 -  22.1s\n",
      "[CV] C=2, gamma=1e-05 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-05, score=0.402351 -  22.3s\n",
      "[CV] C=2, gamma=1e-05 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-05, score=0.402319 -  22.0s\n",
      "[CV] C=2, gamma=1e-05 ................................................\n",
      "[CV] ....................... C=2, gamma=1e-05, score=0.402449 -  22.4s\n",
      "[CV] C=2, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=2, gamma=0.0001, score=0.402351 -  21.9s\n",
      "[CV] C=2, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=2, gamma=0.0001, score=0.402319 -  23.1s\n",
      "[CV] C=2, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=2, gamma=0.0001, score=0.402449 -  22.3s\n",
      "[CV] C=2, gamma=0.001 ................................................\n",
      "[CV] ....................... C=2, gamma=0.001, score=0.402673 -  21.8s\n",
      "[CV] C=2, gamma=0.001 ................................................\n",
      "[CV] ....................... C=2, gamma=0.001, score=0.402319 -  22.2s\n",
      "[CV] C=2, gamma=0.001 ................................................\n",
      "[CV] ....................... C=2, gamma=0.001, score=0.402449 -  22.4s\n",
      "[CV] C=2, gamma=0.01 .................................................\n",
      "[CV] ........................ C=2, gamma=0.01, score=0.480116 -  22.2s\n",
      "[CV] C=2, gamma=0.01 .................................................\n",
      "[CV] ........................ C=2, gamma=0.01, score=0.488646 -  22.9s\n",
      "[CV] C=2, gamma=0.01 .................................................\n",
      "[CV] ........................ C=2, gamma=0.01, score=0.538585 -  23.2s\n",
      "[CV] C=2, gamma=0.1 ..................................................\n",
      "[CV] ......................... C=2, gamma=0.1, score=0.491225 -  21.2s\n",
      "[CV] C=2, gamma=0.1 ..................................................\n",
      "[CV] ......................... C=2, gamma=0.1, score=0.511354 -  21.6s\n",
      "[CV] C=2, gamma=0.1 ..................................................\n",
      "[CV] ......................... C=2, gamma=0.1, score=0.545191 -  22.2s\n",
      "[CV] C=2, gamma=1.0 ..................................................\n",
      "[CV] ......................... C=2, gamma=1.0, score=0.501047 -  22.7s\n",
      "[CV] C=2, gamma=1.0 ..................................................\n",
      "[CV] ......................... C=2, gamma=1.0, score=0.518119 -  23.2s\n",
      "[CV] C=2, gamma=1.0 ..................................................\n",
      "[CV] ......................... C=2, gamma=1.0, score=0.549380 -  23.7s\n",
      "[CV] C=2, gamma=10.0 .................................................\n",
      "[CV] ........................ C=2, gamma=10.0, score=0.489132 -  26.9s\n",
      "[CV] C=2, gamma=10.0 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed: 11.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ C=2, gamma=10.0, score=0.508133 -  26.3s\n",
      "[CV] C=2, gamma=10.0 .................................................\n",
      "[CV] ........................ C=2, gamma=10.0, score=0.536491 -  28.2s\n",
      "[CV] C=2, gamma=100.0 ................................................\n",
      "[CV] ....................... C=2, gamma=100.0, score=0.468846 -  57.6s\n",
      "[CV] C=2, gamma=100.0 ................................................\n",
      "[CV] ....................... C=2, gamma=100.0, score=0.481237 -  58.5s\n",
      "[CV] C=2, gamma=100.0 ................................................\n",
      "[CV] ....................... C=2, gamma=100.0, score=0.503142 -  54.7s\n",
      "[CV] C=2, gamma=1000.0 ...............................................\n",
      "[CV] ...................... C=2, gamma=1000.0, score=0.408308 - 1.0min\n",
      "[CV] C=2, gamma=1000.0 ...............................................\n",
      "[CV] ...................... C=2, gamma=1000.0, score=0.414560 - 1.0min\n",
      "[CV] C=2, gamma=1000.0 ...............................................\n",
      "[CV] ...................... C=2, gamma=1000.0, score=0.415338 -  59.0s\n",
      "[CV] C=4, gamma=1e-09 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-09, score=0.402351 -  17.3s\n",
      "[CV] C=4, gamma=1e-09 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-09, score=0.402319 -  18.0s\n",
      "[CV] C=4, gamma=1e-09 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-09, score=0.402449 -  18.2s\n",
      "[CV] C=4, gamma=1e-08 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-08, score=0.402351 -  20.6s\n",
      "[CV] C=4, gamma=1e-08 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-08, score=0.402319 -  20.9s\n",
      "[CV] C=4, gamma=1e-08 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-08, score=0.402449 -  20.6s\n",
      "[CV] C=4, gamma=1e-07 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-07, score=0.402351 -  21.4s\n",
      "[CV] C=4, gamma=1e-07 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-07, score=0.402319 -  22.7s\n",
      "[CV] C=4, gamma=1e-07 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-07, score=0.402449 -  22.9s\n",
      "[CV] C=4, gamma=1e-06 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-06, score=0.402351 -  21.7s\n",
      "[CV] C=4, gamma=1e-06 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-06, score=0.402319 -  21.9s\n",
      "[CV] C=4, gamma=1e-06 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-06, score=0.402449 -  22.4s\n",
      "[CV] C=4, gamma=1e-05 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-05, score=0.402351 -  22.2s\n",
      "[CV] C=4, gamma=1e-05 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-05, score=0.402319 -  21.7s\n",
      "[CV] C=4, gamma=1e-05 ................................................\n",
      "[CV] ....................... C=4, gamma=1e-05, score=0.402449 -  22.2s\n",
      "[CV] C=4, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=4, gamma=0.0001, score=0.402351 -  21.9s\n",
      "[CV] C=4, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=4, gamma=0.0001, score=0.402319 -  22.2s\n",
      "[CV] C=4, gamma=0.0001 ...............................................\n",
      "[CV] ...................... C=4, gamma=0.0001, score=0.402449 -  22.4s\n",
      "[CV] C=4, gamma=0.001 ................................................\n",
      "[CV] ....................... C=4, gamma=0.001, score=0.429399 -  24.2s\n",
      "[CV] C=4, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-56-c9730ae5a484>\", line 17, in <module>\n",
      "    fitted = clf_grid.fit(X, y)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/grid_search.py\", line 804, in fit\n",
      "    return self._fit(X, y, ParameterGrid(self.param_grid))\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/grid_search.py\", line 553, in _fit\n",
      "    for parameters in parameter_iterable\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 800, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 658, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 566, in _dispatch\n",
      "    job = ImmediateComputeBatch(batch)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 180, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/cross_validation.py\", line 1531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/svm/base.py\", line 193, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/sklearn/svm/base.py\", line 251, in _dense_fit\n",
      "    max_iter=self.max_iter, random_seed=random_seed)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/inspect.py\", line 715, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/inspect.py\", line 684, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/inspect.py\", line 669, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Users/rgap/anaconda/envs/reactions_proj/lib/python3.5/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import grid_search\n",
    "from sklearn import cross_validation as cv\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [ 2**j for j in range(1,4) ],\n",
    "    \"gamma\": np.logspace(-9, 3, 13)\n",
    "}\n",
    "\n",
    "skf = cv.StratifiedKFold(y, n_folds=3)\n",
    "clf_grid = grid_search.GridSearchCV(clf_rbf, \n",
    "                                    param_grid = param_grid,\n",
    "                                    scoring=\"accuracy\",\n",
    "                                    n_jobs=1,\n",
    "                                    cv=skf,\n",
    "                                    verbose=3)\n",
    "fitted = clf_grid.fit(X, y)\n",
    "\n",
    "print (\"best_params_: {}\\n\".format(clf_grid.best_params_))\n",
    "print (\"best_score_: {}\\n\".format(clf_grid.best_score_))\n",
    "\n",
    "print (\"best_score_: {}\\n\".format(clf_grid.grid_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
